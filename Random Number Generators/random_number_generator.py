# -*- coding: utf-8 -*-
"""Random Number Generator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ooqp42P2ZZUcEkVoVNWFZB2tSsiTr0y-
"""

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import style

style.use('seaborn-v0_8-paper')

"""# **1.Uniform disribution Generator**"""

N = 10000

for i in range(1000, N+1, 3000):
  numbers = np.random.randint(0, 10, size = i)
  sns.histplot(numbers, discrete=True, shrink=0.8)
  plt.title(f'$N = {i}$')
  plt.xticks(np.arange(10))
  plt.xlabel('Value')
  plt.tight_layout()
  plt.show()

_ , counts = np.unique(numbers, return_counts = True)
variance = np.sum((counts - N / 10)**2) / (len(counts) - 1)
vars = []
N = 10000

for i in range(100, N):
  numbers = np.random.randint(0, 10, size = i)
  _ , counts = np.unique(numbers, return_counts = True)
  vars.append( np.sqrt(np.sum((counts - i / 10)**2) / (len(counts) - 1))/i)

n = np.arange(100, N)
sns.lineplot(x=n, y=vars)
plt.ylabel(ylabel = '$\sigma$')
plt.xlabel(xlabel = 'the number of generated values')
plt.ylim(0, 0.1)
plt.show()

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
feature = n**(-1/2)
model = LinearRegression().fit(feature.reshape(-1, 1), vars)
p = model.predict(feature.reshape(-1, 1))
mse = mean_squared_error(vars, p)
mse#mse is very low so its agree with the statement in the question that \sigma / N ~ 1/(N)^0.5

plt.plot(feature, vars, label = 'Actual value')
plt.plot(feature, p, color = 'red', label = 'Prediction')
plt.legend()
plt.show()

#now i will use 'chisquare' statistical test for checking whether data follows normal distribution or not
from scipy.stats import chisquare
numbers = np.random.randint(0, 10, size = N)
expected_counts = np.full(10, len(numbers)/10)
_, counts = np.unique(numbers, return_counts = True)

chi2_stat, p_value = chisquare(counts, expected_counts)
p_value#if it is higher than 0.05 then data follows uniform distribution,which here is the case

"""# **2.checking correlation**"""

arr = np.random.randint(0,10,10*N)
mask = np.roll((arr == 4), -1)
mask[-1] = False#we shouldnt pick the last number, cuz there is no number ahead of it
arr = arr[mask]#now the process is as before

sns.histplot(arr, discrete=True, shrink=0.8)
plt.title(f'$N = {len(arr)}$')
plt.xticks(np.arange(10))
plt.xlabel('Value')
plt.tight_layout()
plt.show()



vars = []
n = []
N = 100000

for i in range(1000, N):
  arr = np.random.randint(0, 10, size = i)
  mask = np.roll((arr == 4), -1)
  arr = arr[mask]
  _ , counts = np.unique(arr, return_counts = True)
  vars.append( np.sqrt(np.sum((counts - len(arr) / 10)**2) / (len(counts) - 1))/len(arr))
  n.append(len(arr))

sns.lineplot(x=n, y=vars)
plt.ylabel(ylabel = '$\sigma$')
plt.xlabel(xlabel = 'the number of generated values')
plt.ylim(0, 0.1)
plt.show()

n = np.array(n)
vars = np.array(vars)
feature = n**(-1/2)
model = LinearRegression().fit(feature.reshape(-1, 1), vars)
p = model.predict(feature.reshape(-1, 1))
mse = mean_squared_error(vars, p)
mse

plt.plot(feature, vars, label = 'Actual value')
plt.plot(feature, p, color = 'red', label = 'Prediction')
plt.legend()
plt.show()

"""#3.Linear Congruential Generator"""

def LGC(seed = 42, c = 1013904223, a = 1664525, m = 2**31,size = 1):
  arr = np.zeros(size)
  arr[0] = seed
  for i in range(1, size):
    arr[i] = ((a * arr[i-1] + c) % m)
  return arr

arr = LGC(size = 100000) % 10
sns.histplot(arr, discrete=True, shrink=0.8)
plt.title(f'$N = {len(arr)}$')
plt.xticks(np.arange(10))
plt.xlabel('Value')
plt.tight_layout()
plt.show()

vars = []
n = []
N = 10000

for i in range(1000, N):
  arr = LGC(size = i) % 10
  _ , counts = np.unique(arr, return_counts = True)
  vars.append( np.sqrt(np.sum((counts - len(arr) / 10)**2) / (len(counts) - 1))/len(arr))
  n.append(len(arr))

sns.lineplot(x=n, y=vars)
plt.ylabel(ylabel = '$\sigma$')
plt.xlabel(xlabel = 'the number of generated values')
plt.ylim(0, 0.1)
plt.show()


n = np.array(n)
vars = np.array(vars)
feature = n**(-1/2)
model = LinearRegression().fit(feature.reshape(-1, 1), vars)
p = model.predict(feature.reshape(-1, 1))
mse = mean_squared_error(vars, p)
print(mse)

plt.plot(feature, vars, label = 'Actual value')
plt.plot(feature, p, color = 'red', label = 'Prediction')
plt.legend()
plt.show()

#proccess is the same as before
arr = LGC(size = 10000) % 10
mask = np.roll((arr == 4), -1)
mask[-1] = False#we shouldnt pick the last number, cuz there is no number ahead of it
arr = arr[mask]#now the process is as before

sns.histplot(arr, discrete=True, shrink=0.8)
plt.title(f'$N = {len(arr)}$')
plt.xticks(np.arange(10))
plt.xlabel('Value')
plt.tight_layout()
plt.show()


vars = []
n = []
N = 20000

for i in range(1000, N):
  arr = LGC(size = i) % 10
  mask = np.roll((arr == 4), -1)
  arr = arr[mask]
  _ , counts = np.unique(arr, return_counts = True)
  vars.append( np.sqrt(np.sum((counts - len(arr) / 10)**2) / (len(counts) - 1))/len(arr))
  n.append(len(arr))

sns.lineplot(x=n, y=vars)
plt.ylabel(ylabel = '$\sigma$')
plt.xlabel(xlabel = 'the number of generated values')
plt.show()

n = np.array(n)
vars = np.array(vars)
feature = n**(-1/2)
model = LinearRegression().fit(feature.reshape(-1, 1), vars)
p = model.predict(feature.reshape(-1, 1))
mse = mean_squared_error(vars, p)
print(mse)

plt.plot(feature, vars, label = 'Actual value')
plt.plot(feature, p, color = 'red', label = 'Prediction')
plt.legend()
plt.show()

"""4."""

